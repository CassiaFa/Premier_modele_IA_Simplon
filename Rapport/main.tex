\documentclass[french]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{natbib}
\usepackage[vmargin=3cm,left=4cm,right=4cm]{geometry}

\usepackage{amsmath}

\usepackage{babel}

\usepackage{graphicx}
\usepackage{caption} 
\captionsetup{justification=centering}
\usepackage{subcaption}
% \usepackage{hyperref}
\usepackage[hidelinks]{hyperref}

% ################################
% Package pour incorporer du code
\usepackage{xcolor,colortbl}
\usepackage{listings}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}

\lstdefinestyle{mystyle}{
    literate=
  {²}{{\textsuperscript{2}}}1
  {⁴}{{\textsuperscript{4}}}1
  {⁶}{{\textsuperscript{6}}}1
  {⁸}{{\textsuperscript{8}}}1
  {€}{{\euro{}}}1
  {é}{{\'e}}1
  {è}{{\`{e}}}1
  {ê}{{\^{e}}}1
  {ë}{{\¨{e}}}1
  {É}{{\'{E}}}1
  {Ê}{{\^{E}}}1
  {û}{{\^{u}}}1
  {ù}{{\`{u}}}1
  {â}{{\^{a}}}1
  {à}{{\`{a}}}1
  {á}{{\'{a}}}1
  {ã}{{\~{a}}}1
  {Á}{{\'{A}}}1
  {Â}{{\^{A}}}1
  {Ã}{{\~{A}}}1
  {ç}{{\c{c}}}1
  {Ç}{{\c{C}}}1
  {õ}{{\~{o}}}1
  {ó}{{\'{o}}}1
  {ô}{{\^{o}}}1
  {Õ}{{\~{O}}}1
  {Ó}{{\'{O}}}1
  {Ô}{{\^{O}}}1
  {î}{{\^{i}}}1
  {Î}{{\^{I}}}1
  {í}{{\'{i}}}1
  {Í}{{\~{Í}}}1,
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{blue},
    numberstyle=\color{codegray},
    stringstyle=\color{orange},
    basicstyle=\ttfamily\small, % \footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=10pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,
}

\lstset{style=mystyle}

%##################################


\begin{document}

%###############################################
\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 
%----------------------------------------------------------------------------------------
%	Section Titre
%----------------------------------------------------------------------------------------
\HRule \\[0.4cm]
\vspace{1cm}
{ \huge \bfseries Premier modèle IA}\\ % Title of your document
\vspace{1cm}
\HRule \\[1cm]
 
%----------------------------------------------------------------------------------------
%	Section auteur
%----------------------------------------------------------------------------------------
\vspace{1cm}

\Large \today

\vspace{3cm}

\begin{minipage}{0.4\textwidth}
\begin{center}
\Large \textbf{Auteurs :}\\
\vspace{0.5cm}
Fabio \textsc{Cassiano}
\end{center}
\end{minipage}

\vspace{5cm}

\begin{figure}[!ht]
    %\hspace*{-0.5cm}
	\includegraphics[height=0.1\columnwidth]{images/logo/logo_simplon.png}
	\hspace*{0.5cm}
	\includegraphics[height=0.12\columnwidth]{images/logo/logo_Isen.png}
	\hspace*{0.5cm}
	\includegraphics[height=0.1\columnwidth]{images/logo/logo_microsoft.jpg}
\end{figure}

\vfill

\end{titlepage}

\newpage

\tableofcontents

\newpage

\section{Rappel sur la régression linéaire}

La régression linéaire est une méthode statistique qui a pour objectif de trouver une relation entre une variable cible (\textit{target}) à partir d'une variable dite descriptive. La régression linéaire peut-être appliqué sur différents types de modèles qui vont être abordés dans les sous-section ci-dessous. 

\subsection{Modèle simple}

Le modèle linéaire simple, est un modèle basé sur une fonction affine. Cette fonction a pour équation mathématique :

\begin{center}
    $f(x) = ax + b$
\end{center}

\noindent Dans cette équation $f(x)$ représente la valeur cible, soit celle qu'il faut prédire. La valeur $x$ correspond à la variable descriptive à partir de laquelle on pourra obtenir $f(x)$. Les valeurs a et b correspondent aux coefficients, qui représentent respectivement la pente et l'ordonnée à l'origine. 

\subsection{Modèle multiple}

Le modèle linéaire multiple est une extension du modèle linéaire simple, qui permet la prédiction du variable cible à partir de plusieurs variables descriptives. Ce modèle a pour équation :

\begin{center}
    $f(x) = ax_{1} + bx_{2} + c $
\end{center}

\noindent Tout comme pour l'équation précédente $f(x)$ représente la valeur cible, soit celle qu'il faut prédire. Les valeur $x_{1}$ jusqu'à $x_{n}$ représentent aux différentes variables descriptives de notre jeu de données.

\subsection{Modèle polynomiale}

Concernant le modèle polynomiale, il correspond à une équation à une inconnue, avec un polynôme de degré $n$. Mathématiquement cela se traduit de la manière suivante :

\begin{center}
    $f(x) = ax^{n} + bx^{n-1} + c $
\end{center}

\noindent Par exemple pour un polynomial de degré 2 l'équation est :

\begin{center}
    $f(x) = ax^{2} + bx + c $
\end{center}

\newpage

\section{Fonction sous python}

\subsection{Définition de la fonction \textit{model()}}

Les différents modèles présenté précedement peuvent être retranscrit sous python. Pour facilité leur modélisation on peut les écrire modèles sous forme matricielle.

\subsubsection{Modèle simple}

\noindent L'écriture matricielle du modèle linéaire simple est donc la suivante :
\begin{align*}
    F = X \cdot \theta
\end{align*}

\noindent avec, 
$$X = \begin{bmatrix}
    x^{(1)} & 1 \\
    \vdots & \vdots \\
    x^{(n)} & 1
\end{bmatrix}$$

\noindent et, 
$$\theta = \begin{bmatrix}
    a \\
    b
\end{bmatrix}$$

\noindent où $X$ est la matrice qui contient la variable descriptive $x$, sous forme de colonne. Une colonne composé uniquement de $1$ est également inclut dans $X$, ce qui correspond au multiplicateur du coefficient \textit{b}. Enfin la matrice $\theta$ regroupe les coefficients \textit{a} et \textit{b}.

\subsubsection{Modèle multiple}

Pour le modèle multiple, la forme matricielle est la même que pour le modèle simple. Il suffit d'adapter la matrice $X$ en ajoutant les différentes features que l'on souhaite étudié, et ajouter à la matrice $\theta$ le nombre de coefficient correspondant. Ce qui nous donne :

$$X = \begin{bmatrix}
    x_{1}^{(1)} & x_{2}^{(1)} & 1 \\
    \vdots & \vdots & \vdots\\
    x_{1}^{(n)} & x_{2}^{(n)} & 1
\end{bmatrix}$$

\subsubsection{Modèle polynomiale}

De même pour le modèle polynomiale, il suffit d'adapter la matrice $X$ et $\theta$. Ce qui nous donne :

$$X = \begin{bmatrix}
    x^{2 (1)} & x^{(1)} & 1 \\
    \vdots & \vdots & \vdots \\
    x^{2 (n)} & x^{(n)} & 1
\end{bmatrix}$$

\subsubsection{Code python}

\begin{lstlisting}[language=Python]
# Création de la fonction modélisant le modèle linéaire F
def model(X, theta):
    return X.dot(theta)
\end{lstlisting}

\subsection{Définition de la fonction \textit{fonction\_cout()}}
La fonction de coût permet de mesurer les erreurs entre le modèle calculé et le jeu de données. La formule mathématiquement de cette fonction, pour le linéaire simple, s'écrit de la manière suivante : 

\begin{align*}
    J(a,b) = \dfrac{1}{2m}\sum_{i=1}^{m}(ax + b - y)^2
\end{align*}

\noindent On peut également l'écrire sous forme matricielle, ce qui la généralise pour les autres modèles présenté précédemment. Ce qui donne :

\begin{align*}
    J(\theta) = \dfrac{1}{2m}\sum(X.\theta - y)^2
\end{align*}

\subsubsection{Code python}

\begin{lstlisting}[language=Python]
# Création de la fonction permettant l'estimation de la fonction de coût
def fonction_cout(X, Y, theta):
    m = len(X) # taille de la matrice X
    return (1/(2*m))* np.sum(np.power((model(X, theta) - Y), 2))
\end{lstlisting}

\subsection{Définition de la fonction \textit{gradient()}}
Le gradient permet de caractérisé la variabilité d'une fonction en un point donné. Pour ce faire on calcule les dérivées partielles. Le gradient de notre fonction coût correspond donc aux dérivées partielle selon \textit{a} et selon \textit{b}. Ce qui se traduit par :
\begin{align*}
    \dfrac{\delta J(a,b)}{\delta a} = \dfrac{1}{m}\sum(ax + b - y) \\
    \dfrac{\delta J(a,b)}{\delta b} = \dfrac{1}{m}\sum(ax + b - y)
\end{align*}

\noindent De même ces équations peuvent s'écrire sous forme matricielle :

\begin{align*}
    \dfrac{\delta J(\theta)}{\delta \theta} = \dfrac{1}{m}X^{T}(X.\theta - y)
\end{align*}

\noindent Où $X^{T}$ correspond à la transposé de $X$.

\subsubsection{Code python}

\begin{lstlisting}[language=Python]
# Création de la fonction permettant l'estimation des gradient
def gradient(X, Y, theta):
    m = len(X)
    return (1/m) * X.T.dot((model(X, theta) - Y))
\end{lstlisting}

\newpage

\section{Résultats}
\subsection{Modèle simple}

\subsection{Modèle multiple}

\subsection{Modèle polynomiale}

\newpage


\end{document}
